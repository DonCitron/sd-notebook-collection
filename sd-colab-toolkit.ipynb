{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linaqruf/sd-notebook-collection/blob/main/sd-colab-toolkit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. Installation"
      ],
      "metadata": {
        "id": "akFjukqz5PbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 1.1 Install Dependencies\n",
        "import os\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "# Check if the directory already exists\n",
        "if os.path.isdir('/content/sd-notebook-collection'):\n",
        "  %cd /content/sd-notebook-collection\n",
        "  print(\"This folder already exists, will do a !git pull instead\\n\")\n",
        "  !git pull\n",
        "else:\n",
        "  !git clone https://github.com/Linaqruf/sd-notebook-collection\n",
        "\n",
        "%cd /content/sd-notebook-collection\n",
        "\n",
        "#@markdown This will install required Python packages\n",
        "!pip install --upgrade -r requirements.txt\n",
        "!pip install --upgrade --no-cache-dir gdown\n",
        "!apt install liblz4-tool aria2\n",
        "\n",
        "if not os.path.exists('/content/models'):\n",
        "  os.makedirs('/content/models')\n",
        "\n",
        "if not os.path.exists('/content/vae'):\n",
        "  os.makedirs('/content/vae')\n",
        "\n",
        "if not os.path.exists('/content/output'):\n",
        "  os.makedirs('/content/output')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0BicRIFqIjg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 1.2. Download Available Model \n",
        "%cd /content/\n",
        "import os\n",
        "\n",
        "installModels = []\n",
        "#@markdown ### Available Model\n",
        "#@markdown Select one of available model to download:\n",
        "\n",
        "modelUrl = [\"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animeckpt/model-latest.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animeckpt/model-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-v3-better-vae/resolve/main/any-v3-fp32-better-vae.ckpt\", \\\n",
        "            \"https://huggingface.co/andite/anything-v4.0/resolve/main/anything-v4.0.ckpt\", \\\n",
        "            \"https://huggingface.co/andite/anything-v4.0/resolve/main/anything-v4.0-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/andite/anything-v4.0/resolve/main/anything-v4.5-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/Rasgeath/self_made_sauce/resolve/main/Kani-anime.ckpt\", \\\n",
        "            \"https://huggingface.co/Rasgeath/self_made_sauce/resolve/main/Kani-anime-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/hesw23168/SD-Elysium-Model/resolve/main/Elysium_Anime_V2.ckpt\", \\\n",
        "            \"https://huggingface.co/prompthero/openjourney-v2/resolve/main/openjourney-v2.ckpt\", \\\n",
        "            \"https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0/resolve/main/dreamlike-diffusion-1.0.ckpt\", \\\n",
        "            \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\"]\n",
        "modelList = [\"Animefull-final-latest\", \\\n",
        "             \"Animefull-final-pruned\", \\\n",
        "             \"Anything-V3\", \\\n",
        "             \"Anything-V3-pruned\", \\\n",
        "             \"Anything-V3-better-vae\", \\\n",
        "             \"Anything-V4\", \\\n",
        "             \"Anything-V4-pruned\", \\\n",
        "             \"Anything-V4-5-pruned\", \\\n",
        "             \"Kani-anime\", \\\n",
        "             \"Kani-anime-pruned\", \\\n",
        "             \"Elysium-anime-V2\", \\\n",
        "             \"OpenJourney-V2\", \\\n",
        "             \"Dreamlike-diffusion-V1-0\", \\\n",
        "             \"Stable-Diffusion-v1-5\"]\n",
        "modelName = \"Anything-V4\" #@param [\"Animefull-final-latest\", \"Animefull-final-pruned\", \"Anything-V3\", \"Anything-V3-pruned\", \"Anything-V3-better-vae\", \"Anything-V4\", \"Anything-V4-pruned\", \"Anything-V4-5-pruned\",\"Kani-anime\", \"Kani-anime-pruned\", \"Elysium-anime-V2\", \"OpenJourney-V2\", \"Dreamlike-diffusion-V1-0\", \"Stable-Diffusion-v1-5\"]\n",
        "\n",
        "installModels.append((modelName, modelUrl[modelList.index(modelName)]))\n",
        "\n",
        "def install(checkpoint_name, url):\n",
        "  hf_token = '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' \n",
        "  user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "  !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -o models/{checkpoint_name}.ckpt \"{url}\"\n",
        "\n",
        "def install_checkpoint():\n",
        "  for model in installModels:\n",
        "    install(model[0], model[1])\n",
        "\n",
        "install_checkpoint()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UKP8CU-KNkjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 1.3. Download Custom Model\n",
        "\n",
        "%cd /content/models\n",
        "\n",
        "import os\n",
        "\n",
        "#@markdown ### Custom model\n",
        "modelList = []\n",
        "modelUrl = \"https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/AbyssOrangeMix2/AbyssOrangeMix2_sfw.ckpt\" #@param {'type': 'string'}\n",
        "modelUrl2 = \"\" #@param {'type': 'string'}\n",
        "modelUrl3 = \"\" #@param {'type': 'string'}\n",
        "modelUrl4 = \"\" #@param {'type': 'string'}\n",
        "\n",
        "modelList.extend([modelUrl, \n",
        "                  modelUrl2,\n",
        "                  modelUrl3,\n",
        "                  modelUrl4])\n",
        "\n",
        "def install_aria():\n",
        "  if not os.path.exists('/usr/bin/aria2c'):\n",
        "    !apt install -y -qq aria2\n",
        "\n",
        "def install(url):\n",
        "  if url.startswith(\"https://drive.google.com\"):\n",
        "    !gdown --fuzzy  \"{url}\"\n",
        "  elif url.startswith(\"magnet:?\"):\n",
        "    install_aria()\n",
        "    !aria2c --summary-interval=10 -c -x 10 -k 1M -s 10 \"{url}\"\n",
        "  elif url.startswith(\"https://huggingface.co/\"):\n",
        "    if '/blob/' in url:\n",
        "      url = url.replace('/blob/', '/resolve/')\n",
        "\n",
        "    hf_token = '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'\n",
        "    user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d /content/models -Z \"{url}\"\n",
        "  else:\n",
        "    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d /content/models -Z \"{url}\"\n",
        "\n",
        "def install_checkpoint():\n",
        "  for customModel in modelList:\n",
        "    install(customModel)\n",
        "\n",
        "install_checkpoint()\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "A2NC0tm8vU-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 1.4. Download VAE\n",
        "%cd /content/\n",
        "\n",
        "installVae = []\n",
        "#@markdown ### Available VAE\n",
        "#@markdown Select one of the VAEs to download, select `none` for not download VAE:\n",
        "vaeUrl = [\"\", \\\n",
        "          \"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animevae/animevae.pt\", \\\n",
        "          \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\", \\\n",
        "          \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\"]\n",
        "vaeList = [\"none\", \\\n",
        "           \"anime.vae.pt\", \\\n",
        "           \"waifudiffusion.vae.pt\", \\\n",
        "           \"stablediffusion.vae.pt\"]\n",
        "vaeName = \"anime.vae.pt\" #@param [\"none\", \"anime.vae.pt\", \"waifudiffusion.vae.pt\", \"stablediffusion.vae.pt\"]\n",
        "\n",
        "installVae.append((vaeName, vaeUrl[vaeList.index(vaeName)]))\n",
        "\n",
        "def install(vae_name, url):\n",
        "  hf_token = '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'\n",
        "  user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "  !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -o vae/{vae_name} \"{url}\"\n",
        "\n",
        "def install_vae():\n",
        "  if vaeName != \"none\":\n",
        "    for vae in installVae:\n",
        "      install(vae[0], vae[1])\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "install_vae()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CZJLUBn3MgRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Model Conversion"
      ],
      "metadata": {
        "id": "WDPfF4uc5pd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "#@title ## 2.1. Model Pruner\n",
        "\n",
        "%cd /content/sd-notebook-collection/script\n",
        "\n",
        "#@markdown Convert to Float16\n",
        "fp16 = False #@param {'type':'boolean'}\n",
        "#@markdown Use EMA for weights\n",
        "ema = False #@param {'type':'boolean'}\n",
        "#@markdown Strip CLIP weights\n",
        "no_clip = False #@param {'type':'boolean'}\n",
        "#@markdown Strip VAE weights\n",
        "no_vae = False #@param {'type':'boolean'}\n",
        "#@markdown Strip depth model weights\n",
        "no_depth = False #@param {'type':'boolean'}\n",
        "#@markdown Strip UNet weights\n",
        "no_unet = False #@param {'type':'boolean'}\n",
        "#@markdown You need to input model ends with `.ckpt`, because `.safetensors` model won't work.\n",
        "\n",
        "input = \"/content/models/Anything-V3.ckpt\" #@param {'type' : 'string'}\n",
        "\n",
        "\n",
        "# Notify the user that the model is being loaded\n",
        "print(f\"Loading model from {input}\")\n",
        "\n",
        "input_path = os.path.dirname(input)\n",
        "base_name = os.path.basename(input)\n",
        "output_name = base_name.split('.')[0]\n",
        "# Notify the user of the arguments being used\n",
        "if fp16:\n",
        "    print(\"Converting to float16\")\n",
        "    output_name += '-fp16'\n",
        "if ema:\n",
        "    print(\"Using EMA for weights\")\n",
        "    output_name += '-ema'\n",
        "if no_clip:\n",
        "    print(\"Stripping CLIP weights\")\n",
        "    output_name += '-no-clip'\n",
        "if no_vae:\n",
        "    print(\"Stripping VAE weights\")\n",
        "    output_name += '-no-vae'\n",
        "if no_depth:\n",
        "    print(\"Stripping depth model weights\")\n",
        "    output_name += '-no-depth'\n",
        "if no_unet:\n",
        "    print(\"Stripping UNet weights\")\n",
        "    output_name += '-no-unet'\n",
        "output_name += '-pruned'\n",
        "output_path = os.path.join(input_path, output_name + '.ckpt')\n",
        "\n",
        "\n",
        "!python3 prune.py \"{input}\" \\\n",
        "  \"{output_path}\" \\\n",
        "  {'--fp16' if fp16 else ''} \\\n",
        "  {'--ema' if ema else ''} \\\n",
        "  {'--no-clip' if no_clip else ''} \\\n",
        "  {'--no-vae' if no_vae else ''} \\\n",
        "  {'--no-depth' if no_depth else ''} \\\n",
        "  {'--no-unet' if no_unet else ''}\n",
        "\n",
        "# Notify the user of the output file location\n",
        "print(f\"Saving pruned model to {output_path}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fb3rxuCaSYta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 2.2. Convert Diffusers to `.ckpt/.safetensors`\n",
        "\n",
        "%cd /content/sd-notebook-collection/script/\n",
        "\n",
        "#@markdown ## Define model path\n",
        "weight = \"/content/models/Anything-V3.ckpt\" #@param {'type': 'string'}\n",
        "weight_dir = os.path.dirname(weight)\n",
        "base_name = os.path.splitext(os.path.basename(weight))[0]\n",
        "\n",
        "convert = \"ckpt_safetensors_to_diffusers\" #@param [\"diffusers_to_ckpt_safetensors\", \"ckpt_safetensors_to_diffusers\"] {'allow-input': false}\n",
        "#@markdown ___\n",
        "#@markdown ## Conversion Config\n",
        "#@markdown ___\n",
        "#@markdown ### Diffusers to `.ckpt/.safetensors`\n",
        "use_safetensors = False #@param {'type': 'boolean'}\n",
        "\n",
        "save_precision = \"--float\" #@param [\"--fp16\",\"--bf16\",\"--float\"] {'allow-input': false}\n",
        "\n",
        "#@markdown ### `.ckpt/.safetensors` to Diffusers\n",
        "#@markdown is your model v1 or v2 based Stable Diffusion Model\n",
        "version = \"--v1\" #@param [\"--v1\",\"--v2\"] {'allow-input': false}\n",
        "diffusers = os.path.join(weight_dir, base_name)\n",
        "\n",
        "#@markdown Additional file for diffusers\n",
        "feature_extractor = True #@param {'type': 'boolean'}\n",
        "safety_checker = True #@param {'type': 'boolean'}\n",
        "\n",
        "if use_safetensors:\n",
        "    checkpoint = str(diffusers)+\".safetensors\"\n",
        "else:\n",
        "    checkpoint = str(diffusers)+\".ckpt\"\n",
        "\n",
        "if version == \"--v1\":\n",
        "  reference_model = \"runwayml/stable-diffusion-v1-5\"\n",
        "elif version == \"--v2\":\n",
        "  reference_model = \"stabilityai/stable-diffusion-2-1\"\n",
        "\n",
        "if convert == \"diffusers_to_ckpt_safetensors\":\n",
        "    if not weight.endswith(\".ckpt\") or weight.endswith(\".safetensors\"):\n",
        "        !python convert_diffusers20_original_sd.py \\\n",
        "            \"{weight}\" \\\n",
        "            \"{checkpoint}\"\" \\\n",
        "            {save_precision}\n",
        "\n",
        "else:    \n",
        "    !python convert_diffusers20_original_sd.py \\\n",
        "        \"{weight}\" \\\n",
        "        \"{diffusers}\" \\\n",
        "        {version} \\\n",
        "        --reference_model {reference_model} \n",
        "\n",
        "    url1 = \"https://huggingface.co/CompVis/stable-diffusion-safety-checker/resolve/main/preprocessor_config.json\"\n",
        "    url2 = \"https://huggingface.co/CompVis/stable-diffusion-safety-checker/resolve/main/config.json\"\n",
        "    url3 = \"https://huggingface.co/CompVis/stable-diffusion-safety-checker/resolve/main/pytorch_model.bin\"\n",
        "\n",
        "    if feature_extractor == True:\n",
        "      if not os.path.exists(str(diffusers)+'/feature_extractor'):\n",
        "        os.makedirs(str(diffusers)+'/feature_extractor')\n",
        "      \n",
        "      !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d '{diffusers}/feature_extractor' -Z {url1}\n",
        "\n",
        "    if safety_checker == True:\n",
        "      if not os.path.exists(str(diffusers)+'/safety_checker'):\n",
        "        os.makedirs(str(diffusers)+'/safety_checker')\n",
        "      \n",
        "      !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d '{diffusers}/safety_checker' -Z {url2}\n",
        "      !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d '{diffusers}/safety_checker' -Z {url3}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TdCb8_dSSzzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.3. Replace VAE of Existing Model \n",
        "%cd /content/sd-notebook-collection/script\n",
        "\n",
        "#@markdown You need to input model ends with `.ckpt`, because `.safetensors` model won't work.\n",
        "\n",
        "target_model = \"/content/models/Anything-V3.ckpt\" #@param {'type': 'string'}\n",
        "target_vae = \"/content/vae/anime.vae.pt\" #@param {'type': 'string'}\n",
        "\n",
        "# get the base file name and directory\n",
        "base_name = os.path.basename(target_model)\n",
        "base_dir = os.path.dirname(target_model)\n",
        "\n",
        "# get the file name without extension\n",
        "file_name = os.path.splitext(base_name)[0]\n",
        "\n",
        "# create the new file name\n",
        "new_file_name = file_name + \"-vae-swapped\"\n",
        "\n",
        "# get the file extension\n",
        "file_ext = os.path.splitext(base_name)[1]\n",
        "\n",
        "# create the output file path\n",
        "output_model = os.path.join(base_dir, new_file_name + file_ext)\n",
        "\n",
        "!python merge_vae.py \\\n",
        "  {target_model} \\\n",
        "  {target_vae} \\\n",
        "  {output_model}\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "g2QfhhlfbGsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.4. Convert CKPT to Safetensors\n",
        "%cd /content/sd-notebook-collection/script\n",
        "\n",
        "target_model = \"/content/models/Anything-V3-vae-swapped.ckpt\" #@param {'type': 'string'}\n",
        "\n",
        "!python convert_to_safetensors.py \\\n",
        "  --input-model {target_model} \\\n",
        "  --device gpu"
      ],
      "metadata": {
        "cellView": "form",
        "id": "e73cbbgIb2cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Deployment "
      ],
      "metadata": {
        "id": "CM-8uH-77BU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 3.1. Login to Huggingface hub\n",
        "from huggingface_hub import login\n",
        "\n",
        "#@markdown 1. Of course, you need a Huggingface account first.\n",
        "#@markdown 2. To create a huggingface token, go to [this link](https://huggingface.co/settings/tokens), then `create new token` or copy available token with the `Write` role.\n",
        "\n",
        "write_token = \"your-write-token-here\" #@param {type:\"string\"}\n",
        "login(write_token, add_to_git_credential=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cxKMspPO7OrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 3.2. Define your Huggingface Repo\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "\n",
        "api = HfApi()\n",
        "user = api.whoami(write_token)\n",
        "\n",
        "#@markdown #### If your model repo didn't exist, it will automatically create your repo.\n",
        "model_name = \"Anything-V3-better-vae\" #@param{type:\"string\"}\n",
        "make_this_model_private = False #@param{type:\"boolean\"}\n",
        "clone_with_git = True #@param{type:\"boolean\"}\n",
        "\n",
        "model_repo = user['name']+\"/\"+model_name.strip()\n",
        "\n",
        "validate_repo_id(model_repo)\n",
        "\n",
        "if make_this_model_private:\n",
        "  private_repo = True\n",
        "else:\n",
        "  private_repo = False\n",
        "\n",
        "if model_name != \"\":\n",
        "  try:\n",
        "      api.create_repo(repo_id=model_repo, \n",
        "                      private=private_repo)\n",
        "      print(\"Model Repo didn't exists, creating repo\")\n",
        "      print(\"Model Repo: \",model_repo,\"created!\\n\")\n",
        "\n",
        "  except HfHubHTTPError as e:\n",
        "      print(f\"Model Repo: {model_repo} exists, skipping create repo\\n\")\n",
        "\n",
        "if clone_with_git:\n",
        "  !git lfs uninstall\n",
        "\n",
        "  if model_name != \"\":\n",
        "    !git clone https://huggingface.co/{model_repo} /content/{model_name}\n",
        "  "
      ],
      "metadata": {
        "cellView": "form",
        "id": "QTXsM170GUpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3. Upload to Huggingface"
      ],
      "metadata": {
        "id": "yUNkWbMHcbiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 3.3.1. Quick Upload to Huggingface\n",
        "from huggingface_hub import HfApi\n",
        "from pathlib import Path\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "#@markdown #### This will be uploaded to model repo\n",
        "#@markdown You can't upload 7G model using `hf_hub` in Colab, please use `!git commit` cell below\n",
        "\n",
        "model_path = \"/content/models/Anything-V3-vae-swapped.safetensors\" #@param {type :\"string\"}\n",
        "path_in_repo = \"Anything-V3-vae-swapped.safetensors\" #@param {type :\"string\"}\n",
        "\n",
        "is_diffusers_model = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown #### Other Information\n",
        "commit_message = \"feat: upload Anything-V3-vae-swapped.safetensors\" #@param {type :\"string\"}\n",
        "\n",
        "\n",
        "if model_path != \"\":\n",
        "  path_obj = Path(model_path)\n",
        "  trained_model = path_obj.parts[-1]\n",
        "\n",
        "  if model_path.endswith(\".ckpt\") or model_path.endswith(\".safetensors\") or model_path.endswith(\".pt\"):\n",
        "    print(f\"Uploading {trained_model} to https://huggingface.co/\"+model_repo)\n",
        "    print(f\"Please wait...\")\n",
        "    \n",
        "    if path_in_repo != \"\":\n",
        "      path_in_repo = trained_model\n",
        "\n",
        "    api.upload_file(\n",
        "        path_or_fileobj=model_path,\n",
        "        path_in_repo=trained_model,\n",
        "        repo_id=model_repo,\n",
        "        commit_message=commit_message,\n",
        "    )\n",
        "    \n",
        "    print(f\"Upload success, located at https://huggingface.co/\"+model_repo+\"/blob/main/\"+trained_model+\"\\n\")\n",
        "  \n",
        "  elif is_diffusers_model == True:\n",
        "    print(f\"Uploading {trained_model} to https://huggingface.co/\"+model_repo)\n",
        "    print(f\"Please wait...\")\n",
        "\n",
        "    api.upload_folder(\n",
        "        folder_path=model_path,\n",
        "        repo_id=model_repo,\n",
        "        commit_message=commit_message,\n",
        "        ignore_patterns=\".ipynb_checkpoints\"\n",
        "    )\n",
        "    print(f\"Upload success, located at https://huggingface.co/\"+model_repo+\"/tree/main\\n\")\n",
        "  \n",
        "  else:\n",
        "    print(f\"Uploading {trained_model} to https://huggingface.co/\"+model_repo)\n",
        "    print(f\"Please wait...\")\n",
        "\n",
        "    api.upload_folder(\n",
        "        folder_path=model_path,\n",
        "        path_in_repo=trained_model,\n",
        "        repo_id=model_repo,\n",
        "        commit_message=commit_message,\n",
        "        ignore_patterns=\".ipynb_checkpoints\"\n",
        "    )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pSUhgYLYdT2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 3.3.2. Or Commit using Git \n",
        "%cd /content/\n",
        "\n",
        "#@markdown Set **git commit identity**\n",
        "email = \"your-email\" #@param {'type': 'string'}\n",
        "name = \"your-username\" #@param {'type': 'string'}\n",
        "#@markdown Set **commit message**\n",
        "commit_m = \"feat: upload Anything-V3-vae-swapped.safetensors\" #@param {'type': 'string'}\n",
        "\n",
        "%cd /content/{model_name}\n",
        "\n",
        "!git lfs install\n",
        "!huggingface-cli lfs-enable-largefiles .\n",
        "!git config --global user.email \"{email}\"\n",
        "!git config --global user.name \"{name}\"\n",
        "!git add .\n",
        "!git lfs help smudge\n",
        "!git commit -m \"{commit_m}\"\n",
        "!git push\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7bJev4PzOFFB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
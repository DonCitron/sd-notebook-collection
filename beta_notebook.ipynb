{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linaqruf/sd-notebook-collection/blob/dev/beta_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![visitor][visitor-badge]][visitor-stats] \n",
        "[![ko-fi][ko-fi-badge]][ko-fi-link]\n",
        "\n",
        "# **Cagliostro Colab UI**\n",
        "All-in-One, Customizable and Flexible Stable Diffusion for Google Colab.\n",
        "\n",
        "V3 | [Github][link-to-github] | [What's New?][README] | [Pocketbook Guide][MANUAL]\n",
        "\n",
        "<!-- [visitor-badge]: https://visitor-badge.glitch.me/badge?page_id=linaqruf.cag-webui -->\n",
        "[visitor-badge]: https://api.visitorbadge.io/api/visitors?path=Cagliostro%20Colab%20UI&label=Visitors&labelColor=%2334495E&countColor=%231ABC9C&style=flat&labelStyle=none\n",
        "[visitor-stats]: https://visitorbadge.io/status?path=Cagliostro%20Colab%20UI\n",
        "[ko-fi-badge]: https://img.shields.io/badge/Support%20me%20on%20Ko--fi-F16061?logo=ko-fi&logoColor=white&style=flat\n",
        "[ko-fi-link]: https://ko-fi.com/linaqruf\n",
        "[link-to-github]: https://github.com/Linaqruf/sd-notebook-collection/blob/main/cagliostro-colab-ui.ipynb\n",
        "[README]: https://github.com/Linaqruf/sd-notebook-collection/blob/main/README.md#whats-new\n",
        "[MANUAL]: https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#cagliostro-colab-ui-user-manual\n",
        "\n"
      ],
      "metadata": {
        "id": "WgQr3s96015a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Install Cagliostro Colab UI** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#install-stable-diffusion-web-ui)</small></small>\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import base64\n",
        "import shutil\n",
        "import subprocess\n",
        "from google.colab.output import eval_js\n",
        "from IPython.utils import capture\n",
        "from tqdm import tqdm\n",
        "subprocess.run(['pip', 'install', '--upgrade', 'git+https://github.com/Linaqruf/colablib'])\n",
        "from colablib.colored_print import cprint\n",
        "from colablib.utils import py_utils, config_utils, package_utils\n",
        "from colablib.utils.ubuntu_utils import ubuntu_deps\n",
        "from colablib.sd_models.downloader import aria2_download\n",
        "from colablib.utils.git_utils import update_repo, batch_update, validate_repo, reset_repo\n",
        "\n",
        "%store -r\n",
        "\n",
        "################################\n",
        "# COLAB ARGUMENTS GOES HERE\n",
        "################################\n",
        "\n",
        "# @markdown ### **Drive Config**\n",
        "mount_drive         = False  # @param {type:'boolean'}\n",
        "output_drive_folder = \"cagliostro-colab-ui/outputs\" #@param {type:'string'}\n",
        "launch_in_drive     = False  # @param {type:'boolean'}\n",
        "# @markdown ### **Repo Config**\n",
        "repo_type           = \"Anapnoe\" #@param [\"AUTOMATIC1111\", \"AUTOMATIC1111-Dev\", \"Anapnoe\", \"Vladmandic\"]\n",
        "update_webui        = True  # @param {type:'boolean'}\n",
        "update_extensions   = True  # @param {type:'boolean'}\n",
        "commit_hash         = \"\"  # @param {type:'string'}\n",
        "dpm_v2_patch        = False  # @param {type:'boolean'}\n",
        "# @markdown > It's not recommended to set params below to `True` if you have **Colab Pro** subscription.\n",
        "ram_alloc_patch     = True  # @param {type:'boolean'}\n",
        "colab_optimizations = True  # @param {type:'boolean'}\n",
        "\n",
        "################################\n",
        "# DIRECTORY CONFIG\n",
        "################################\n",
        "\n",
        "# ROOT DIR\n",
        "root_dir            = \"/content\"\n",
        "drive_dir           = os.path.join(root_dir, \"drive\", \"MyDrive\")\n",
        "\n",
        "if launch_in_drive:\n",
        "    root_dir        = drive_dir\n",
        "\n",
        "repo_dir            = os.path.join(root_dir, \"cagliostro-colab-ui\")\n",
        "tmp_dir             = os.path.join(root_dir, \"tmp\")\n",
        "patches_dir         = os.path.join(root_dir, \"patches\")\n",
        "deps_dir            = os.path.join(root_dir, \"deps\")\n",
        "fused_dir           = os.path.join(root_dir, \"fused\")\n",
        "\n",
        "# REPO DIR\n",
        "models_dir          = os.path.join(repo_dir, \"models\", \"Stable-diffusion\")\n",
        "vaes_dir            = os.path.join(repo_dir, \"models\", \"VAE\")\n",
        "hypernetworks_dir   = os.path.join(repo_dir, \"models\", \"hypernetworks\")\n",
        "lora_dir            = os.path.join(repo_dir, \"models\", \"Lora\")\n",
        "control_dir         = os.path.join(repo_dir, \"models\", \"ControlNet\")\n",
        "esrgan_dir          = os.path.join(repo_dir, \"models\", \"ESRGAN\")\n",
        "embeddings_dir      = os.path.join(repo_dir, \"embeddings\")\n",
        "extensions_dir      = os.path.join(repo_dir, \"extensions\")\n",
        "config_file         = os.path.join(repo_dir, \"config.json\")\n",
        "style_path          = os.path.join(repo_dir, \"style.css\")\n",
        "\n",
        "# VAR\n",
        "voldemort           = base64.b64decode((\"'c3RhYmxlLWRpZmZ1c2lvbi13ZWJ1aQ=='\").encode('ascii')).decode('ascii')\n",
        "output_subdir       = [\"txt2img-images\", \"img2img-images\", \"extras-images\", \"txt2img-grids\", \"img2img-grids\"]\n",
        "\n",
        "################################\n",
        "# REPO TYPE CONFIG\n",
        "################################\n",
        "\n",
        "package_url = [\n",
        "    f\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/{repo_type.lower()}-webui.tar.lz4\",\n",
        "    f\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/{repo_type.lower()}-webui-deps.tar.lz4\",\n",
        "    f\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/{repo_type.lower()}-webui-cache.tar.lz4\",\n",
        "]\n",
        "\n",
        "repo_type_to_repo_name = {\n",
        "    \"anapnoe\"           : f\"anapnoe/{voldemort}-ux\",\n",
        "    \"automatic1111\"     : f\"AUTOMATIC1111/{voldemort}\",\n",
        "    \"automatic1111-dev\" : f\"AUTOMATIC1111/{voldemort}\",\n",
        "    \"vladmandic\"        : f\"vladmandic/automatic\"\n",
        "}\n",
        "\n",
        "branch_type_to_branch = {\n",
        "    \"automatic1111\"     : \"master\",\n",
        "    \"automatic1111-dev\" : \"dev\"\n",
        "}\n",
        "\n",
        "if repo_type.lower() == \"vladmandic\":\n",
        "    embeddings_dir      = os.path.join(repo_dir, \"models\", \"embeddings\")\n",
        "    output_subdir       = [\"text\", \"images\", \"extras\", \"grids\", \"save\"]\n",
        "    dpm_v2_patch        = False\n",
        "    update_webui        = False\n",
        "    colab_optimization  = False\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    for dir in [\"root_dir\", \"fused_dir\", \"repo_dir\", \n",
        "                \"tmp_dir\", \"models_dir\", \"vaes_dir\", \n",
        "                \"hypernetworks_dir\", \"embeddings_dir\", \"extensions_dir\", \n",
        "                \"lora_dir\", \"control_dir\", \"esrgan_dir\"]:\n",
        "        %store {dir}\n",
        "    del cap\n",
        "\n",
        "def mount_func(directory):\n",
        "    output_dir = os.path.join(repo_dir, \"outputs\")\n",
        "\n",
        "    if mount_drive:\n",
        "        if not os.path.exists(directory):\n",
        "            cprint(\"Mounting google drive...\", color=\"green\", reset=False)\n",
        "            drive.mount(os.path.dirname(directory))\n",
        "        output_dir  = os.path.join(directory, output_drive_folder)\n",
        "        cprint(\"Set default output path to:\", output_dir, color=\"green\")\n",
        "        cprint()\n",
        "\n",
        "    return output_dir\n",
        "\n",
        "def setup_directories():\n",
        "    for dir in [fused_dir, models_dir, vaes_dir, \n",
        "                hypernetworks_dir, embeddings_dir, extensions_dir, \n",
        "                lora_dir, control_dir, esrgan_dir]:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "def pre_download(dir, urls, desc, overwrite=False):\n",
        "    gpu_info          = py_utils.get_gpu_info()\n",
        "    version           = py_utils.get_python_version()\n",
        "    xformers_version  = \"0.0.20\"\n",
        "    python_path       = f\"/usr/local/lib/python{version}/dist-packages/\"\n",
        "    ffmpy_path        = os.path.join(python_path, \"ffmpy-0.3.0.dist-info\")\n",
        "\n",
        "    for url in tqdm(urls, desc=desc):\n",
        "        filename  = py_utils.get_filename(url)\n",
        "        aria2_download(dir, filename, url, quiet=True)\n",
        "        if filename == f\"{repo_type.lower()}-webui-deps.tar.lz4\":\n",
        "            package_utils.extract_package(filename, python_path, overwrite=True)\n",
        "        else:\n",
        "            package_utils.extract_package(filename, \"/\", overwrite=overwrite)\n",
        "        os.remove(filename)\n",
        "\n",
        "    if os.path.exists(ffmpy_path):\n",
        "        shutil.rmtree(ffmpy_path)\n",
        "\n",
        "    if repo_type.lower() == \"vladmandic\":\n",
        "        subprocess.run(['pip', 'install', 'ffmpy'], check=True)\n",
        "        \n",
        "    if not repo_type.lower() == \"vladmandic\":\n",
        "        if not 'T4' in gpu_info:\n",
        "            subprocess.run(['pip', 'uninstall', '-y', 'xformers'], check=True)\n",
        "            subprocess.run(['pip', 'install', '-q', f'xformers=={xformers_version}'], check=True)\n",
        "\n",
        "def install_dependencies():\n",
        "    ubuntu_deps_url = \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/ubuntu-deps.zip\"\n",
        "    ram_patch_url   = \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/ram_patch.zip\"\n",
        "\n",
        "    ubuntu_deps(ubuntu_deps_url, deps_dir, cprint(\"Installing ubuntu dependencies\", color=\"green\", tqdm_desc=True))\n",
        "\n",
        "    if ram_alloc_patch:\n",
        "        subprocess.run([\"apt\", \"install\",  'libunwind8-dev', \"-y\"], check=True)\n",
        "        ubuntu_deps(ram_patch_url, deps_dir, cprint(\"Installing RAM allocation patch\", color=\"green\", tqdm_desc=True))\n",
        "        os.environ[\"LD_PRELOAD\"] = \"libtcmalloc.so\"\n",
        "\n",
        "def install_webui(repo_dir, desc):\n",
        "    try:\n",
        "        if not os.path.exists(repo_dir):\n",
        "            pre_download(root_dir, package_url, desc, overwrite=False)\n",
        "            return\n",
        "        \n",
        "        repo_name, _, current_branch = validate_repo(repo_dir)\n",
        "        repo_type_lower = repo_type.lower()\n",
        "        expected_repo_name = repo_type_to_repo_name.get(repo_type_lower)\n",
        "        \n",
        "        if expected_repo_name == repo_name:\n",
        "            expected_branch = branch_type_to_branch.get(repo_type_lower)\n",
        "            if expected_branch is None or expected_branch == current_branch:\n",
        "                cprint(f\"'{repo_name}' {current_branch if expected_branch else ''} already installed, skipping...\", color=\"green\")\n",
        "                return\n",
        "\n",
        "        cprint(f\"Another repository exist. Uninstall '{repo_name}'...\", color=\"green\")\n",
        "        shutil.rmtree(repo_dir)  \n",
        "        pre_download(root_dir, package_url, desc)\n",
        "    except Exception as e:\n",
        "        cprint(f\"An error occurred: {e}\", color=\"green\")\n",
        "\n",
        "def configure_output_path(config_path, output_dir, output_subdir):\n",
        "    config = config_utils.read_config(config_path)\n",
        "    config_updates = {\n",
        "        \"outdir_txt2img_samples\"  : os.path.join(output_dir, output_subdir[0]),\n",
        "        \"outdir_img2img_samples\"  : os.path.join(output_dir, output_subdir[1]),\n",
        "        \"outdir_extras_samples\"   : os.path.join(output_dir, output_subdir[2]),\n",
        "        \"outdir_txt2img_grids\"    : os.path.join(output_dir, output_subdir[3]),\n",
        "        \"outdir_img2img_grids\"    : os.path.join(output_dir, output_subdir[4])\n",
        "    }\n",
        "\n",
        "    config.update(config_updates)\n",
        "    config_utils.write_config(config_path, config)\n",
        "\n",
        "    for dir in output_subdir:\n",
        "        os.makedirs(os.path.join(output_dir, dir), exist_ok=True)\n",
        "\n",
        "def prepare_environment():\n",
        "    cprint(f\"Preparing environment...\", color=\"green\")\n",
        "\n",
        "    os.environ[\"colab_url\"]               = eval_js(\"google.colab.kernel.proxyPort(7860, {'cache': false})\")\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]    = \"3\"\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"]    = \"1\"\n",
        "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = \"garbage_collection_threshold:0.9,max_split_size_mb:512\"\n",
        "    os.environ[\"PYTHONWARNINGS\"]          = \"ignore\"\n",
        "\n",
        "def main():\n",
        "    global output_dir\n",
        "\n",
        "    os.chdir(root_dir)\n",
        "    start_time = time.time()\n",
        "    \n",
        "    output_dir = mount_func(drive_dir)\n",
        "\n",
        "    gpu_info    = py_utils.get_gpu_info(get_gpu_name=True)\n",
        "    python_info = py_utils.get_python_version()\n",
        "    torch_info  = py_utils.get_torch_version()\n",
        "\n",
        "    print_line = \"============================================================================================\"\n",
        "\n",
        "    cprint(print_line, color=\"green\")\n",
        "    cprint(f\"Current GPU:\", gpu_info, color=\"green\")\n",
        "    cprint(f\"Python\", python_info, color=\"green\")\n",
        "    cprint(f\"Torch\", torch_info, color=\"green\")\n",
        "    cprint(print_line, color=\"green\")\n",
        "\n",
        "    install_dependencies()\n",
        "\n",
        "    cprint(print_line, color=\"green\")\n",
        "    install_webui(repo_dir, cprint(f\"Unpacking {repo_type} Webui\", color=\"green\", tqdm_desc=True))\n",
        "    prepare_environment()\n",
        "    setup_directories ()\n",
        "    configure_output_path(config_file, output_dir, output_subdir)\n",
        "\n",
        "    cprint(print_line, color=\"green\")\n",
        "    if update_webui and not commit_hash:\n",
        "        update_repo(cwd=repo_dir, args=\"-X theirs --rebase --autostash\")\n",
        "\n",
        "    if commit_hash:\n",
        "        reset_repo(repo_dir, commit_hash)\n",
        "\n",
        "    repo_name, current_commit_hash, current_branch = validate_repo(repo_dir)\n",
        "    cprint(f\"Using '{repo_name}' repository...\", color=\"green\")\n",
        "    cprint(f\"Branch: {current_branch}, Commit hash: {current_commit_hash}\", color=\"green\")\n",
        "\n",
        "    cprint(print_line, color=\"green\")\n",
        "\n",
        "    if dpm_v2_patch:\n",
        "        os.makedirs(patches_dir)\n",
        "        dpm_v2_url  = \"https://gist.github.com/neggles/75eaacb3f49c209636be61fa96ca95ca/raw/f8c6382f0af65038149fd4258f8462697b698073/01-add-DPMPP-2M-V2.patch\"\n",
        "        dpm_v2_file = os.path.join(patches_dir, '01-add-DPMPP-2M-V2.patch')\n",
        "        subprocess.run(['wget', dpm_v2_url, '-P', patches_dir, '-c'])\n",
        "        subprocess.run(['git', 'apply', '--whitespace=fix', dpm_v2_file], cwd=repo_dir)\n",
        "        shutil.rmtree(patches_dir)\n",
        "\n",
        "    if colab_optimizations:\n",
        "        subprocess.run([\"sed\", \"-i\", f\"s@os.path.splitext(checkpoint_file)@os.path.splitext(checkpoint_file); map_location='cuda'@\", os.path.join(repo_dir, \"modules\", \"sd_models.py\")])\n",
        "        subprocess.run([\"sed\", \"-i\", f\"s@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@\", os.path.join(repo_dir, \"webui.py\")])\n",
        "        subprocess.run([\"sed\", \"-i\", f\"s@map_location='cpu'@map_location='cuda'@\", os.path.join(repo_dir, \"modules\", \"extras.py\")])\n",
        "\n",
        "    if update_extensions:\n",
        "        batch_update(fetch=True, directory=extensions_dir, desc=cprint(f\"Updating extensions\", color=\"green\", tqdm_desc=True))\n",
        "\n",
        "    elapsed_time = py_utils.calculate_elapsed_time(start_time)\n",
        "    cprint(print_line, color=\"green\")\n",
        "    cprint(f\"Finished installation. Took {elapsed_time}.\", color=\"green\")\n",
        "    cprint(\"All is done! Go to the next step.\", color=\"green\")\n",
        "    cprint(print_line, color=\"green\")\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "A6c7-qjDdb0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Download Model and VAE** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#download-model-and-vae)</small></small>\n",
        "import os\n",
        "from colablib.utils import py_utils\n",
        "from colablib.sd_models.downloader import aria2_download, get_modelname\n",
        "\n",
        "# @markdown ### **Stable Diffusion v1.x Model**\n",
        "Anything_V3_0         = False  # @param {type: 'boolean'}\n",
        "AnyLoRA_Default       = False  # @param {type: 'boolean'}\n",
        "AnyLoRA_Anime_Mix     = True  # @param {type: 'boolean'}\n",
        "Ghost_Note_Delta      = False  # @param {type: 'boolean'}\n",
        "SDHK_V3               = False  # @param {type: 'boolean'}\n",
        "Majic_Mix_V5          = False  # @param {type: 'boolean'}\n",
        "# @markdown ### **Stable Diffusion v2.x Model**\n",
        "Replicant_V3          = False  # @param {type: 'boolean'}\n",
        "Illuminati_Diffusion  = False  # @param {type: 'boolean'}\n",
        "# @markdown ### **VAE Model**\n",
        "Anime_VAE             = True  # @param {type: 'boolean'}\n",
        "Blessed_VAE           = False  # @param {type: 'boolean'}\n",
        "Waifu_Diffusion_VAE   = False  # @param {type: 'boolean'}\n",
        "Stable_Diffusion_VAE  = False  # @param {type: 'boolean'}\n",
        "\n",
        "read_token  = \"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\"\n",
        "user_header = f\"Authorization: Bearer {read_token}\"\n",
        "\n",
        "model_dict = {\n",
        "    \"Anything_V3_0\"         : \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/anything-v3-0-pruned.ckpt\",\n",
        "    \"AnyLoRA_Default\"       : \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/AnyLoRA_noVae_fp16-pruned.safetensors\",\n",
        "    \"AnyLoRA_Anime_Mix\"     : \"https://huggingface.co/Linaqruf/stolen/resolve/main/fp16/aamAnyloraAnimeMixAnime_v10-fp16-pruned.safetensors\",\n",
        "    \"Ghost_Note_Delta\"      : \"https://huggingface.co/Linaqruf/stolen/resolve/main/fp16/GhostNoteDelta_m0528_fp16.safetensors\",\n",
        "    \"SDHK_V3\"               : \"https://huggingface.co/Linaqruf/stolen/resolve/main/fp16/sdhk_v30.safetensors\",\n",
        "    \"Majic_Mix_V5\"          : \"https://huggingface.co/Linaqruf/stolen/resolve/main/fp16/majicmixRealistic_v5.safetensors\",\n",
        "    \"Replicant_V3\"          : \"https://huggingface.co/gsdf/Replicant-V3.0/resolve/main/Replicant-V3.0_fp16.safetensors\",\n",
        "    \"Illuminati_Diffusion\"  : \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/illuminatiDiffusionV1_v11.safetensors\",\n",
        "}\n",
        "\n",
        "vae_dict = {\n",
        "    \"Anime_VAE\"             : \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/vae/animevae.pt\",\n",
        "    \"Blessed_VAE\"           : \"https://huggingface.co/NoCrypt/blessed_vae/resolve/main/blessed2.vae.pt\",\n",
        "    \"Waifu_Diffusion_VAE\"   : \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\",\n",
        "    \"Stable_Diffusion_VAE\"  : \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\",    \n",
        "}\n",
        "\n",
        "def filter_dict_items(dict_items):\n",
        "    result_list = []\n",
        "    for key, url in dict_items.items():\n",
        "        if globals().get(key):\n",
        "            result_list.append((key, url))\n",
        "    return result_list\n",
        "\n",
        "def main():\n",
        "    start_time = time.time()\n",
        "    \n",
        "    download_list = [\n",
        "        (filter_dict_items(model_dict), models_dir),\n",
        "        (filter_dict_items(vae_dict), vaes_dir)\n",
        "    ]\n",
        "\n",
        "    print_line = \"============================================================================================\"\n",
        "    cprint(print_line, color=\"green\")\n",
        "    cprint(\"Downloading Stable Diffusion Models and VAEs...\", color=\"green\")\n",
        "    for lst, dst in download_list:\n",
        "        for key, url in lst:\n",
        "            cprint(print_line, color=\"green\")\n",
        "            extensions = os.path.splitext(get_modelname(url))[1]\n",
        "            aria2_download(url=url, download_dir=dst, filename=key + extensions, user_header=user_header)\n",
        "\n",
        "    elapsed_time = py_utils.calculate_elapsed_time(start_time)\n",
        "    cprint(print_line, color=\"green\")\n",
        "    cprint(f\"Download finished. Took {elapsed_time}.\", color=\"green\")\n",
        "    cprint(\"All is done! Go to the next step.\", color=\"green\")\n",
        "    cprint(print_line, color=\"green\")\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "7nUM-wRFhBa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **ControlNet v1.1** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#controlnet-v11)</small></small>\n",
        "\n",
        "# @markdown ### **ControlNet Annotator**\n",
        "pre_download_annotator = True  # @param {type: 'boolean'}\n",
        "# @markdown ### **SDv1.x ControlNet Model**\n",
        "control_v11_sd15_model = True  # @param {type: 'boolean'}\n",
        "t2i_adapter_model = False  # @param {type: 'boolean'}\n",
        "# @markdown ### **SDv2.x ControlNet Model**\n",
        "control_v11_sd21_model = False  # @param {type: 'boolean'}\n",
        "# @markdown ### **ControlNet Config**\n",
        "control_net_max_models_num = 2 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "config_file = os.path.join(repo_dir, \"config.json\")\n",
        "\n",
        "annotator_dict = {\n",
        "    \"midas\"         : \"https://huggingface.co/lllyasviel/ControlNet/resolve/main/annotator/ckpts/dpt_hybrid-midas-501f0c75.pt\",\n",
        "    \"leres\"         : [\n",
        "        \"https://huggingface.co/lllyasviel/Annotators/resolve/main/res101.pth\",\n",
        "        \"https://huggingface.co/lllyasviel/Annotators/resolve/main/latest_net_G.pth\"\n",
        "    ],\n",
        "    \"hed\"           : \"https://huggingface.co/lllyasviel/Annotators/resolve/main/ControlNetHED.pth\",\n",
        "    \"mlsd\"          : \"https://huggingface.co/lllyasviel/ControlNet/resolve/main/annotator/ckpts/mlsd_large_512_fp32.pth\",\n",
        "    \"openpose\"      : [\n",
        "        \"https://huggingface.co/lllyasviel/Annotators/resolve/main/body_pose_model.pth\",\n",
        "        \"https://huggingface.co/lllyasviel/Annotators/resolve/main/hand_pose_model.pth\",\n",
        "        \"https://huggingface.co/lllyasviel/Annotators/resolve/main/facenet.pth\"\n",
        "    ],\n",
        "    \"clip_vision\"   : \"https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/pytorch_model.bin\",\n",
        "    \"pidinet\"       : \"https://huggingface.co/lllyasviel/Annotators/resolve/main/table5_pidinet.pth\",\n",
        "    \"uniformer\"     : \"https://huggingface.co/lllyasviel/ControlNet/resolve/main/annotator/ckpts/upernet_global_small.pth\",\n",
        "    \"zoedepth\"      : \"https://huggingface.co/lllyasviel/Annotators/resolve/main/ZoeD_M12_N.pt\",\n",
        "    \"normal_bae\"    : \"https://huggingface.co/lllyasviel/Annotators/resolve/main/scannet.pt\",\n",
        "    \"oneformer\"     : [\n",
        "        \"https://huggingface.co/lllyasviel/Annotators/resolve/main/150_16_swin_l_oneformer_coco_100ep.pth\",\n",
        "        \"https://huggingface.co/lllyasviel/Annotators/resolve/main/250_16_swin_l_oneformer_ade20k_160k.pth\"\n",
        "    ],\n",
        "    \"lineart\"       : [\n",
        "        \"https://huggingface.co/lllyasviel/Annotators/resolve/main/sk_model.pth\",\n",
        "        \"https://huggingface.co/lllyasviel/Annotators/resolve/main/sk_model2.pth\"\n",
        "    ],\n",
        "    \"lineart_anime\" : \"https://huggingface.co/lllyasviel/Annotators/resolve/main/netG.pth\",\n",
        "    \"manga_line\"    : \"https://huggingface.co/lllyasviel/Annotators/resolve/main/erika.pth\"\n",
        "}\n",
        "\n",
        "control_v11_sd15_url = [\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_lineart_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_openpose_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_scribble_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_seg_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_softedge_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11f1e_sd15_tile_fp16.safetensors\",\n",
        "]\n",
        "\n",
        "control_v11_sd21_url = [\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_ade20k.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_canny.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_color.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_depth.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_hed.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_lineart.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_normalbae.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_openpose.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_openposev2.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_scribble.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_zoedepth.safetensors\"\n",
        "]\n",
        "\n",
        "t2i_adapter_url = [\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd15v2.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_color_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd15v2.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_keypose_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_openpose_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_seg_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd15v2.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_style_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_zoedepth_sd15v1.pth\"\n",
        "]\n",
        "\n",
        "def download_annotator(directory, desc):\n",
        "    for category, urls in tqdm(annotator_dict.items(), desc=cprint(desc, color=\"green\", tqdm_desc=True)):\n",
        "        if category == \"clip_vision\":\n",
        "            dst = os.path.join(directory, \"clip_vision\")\n",
        "        else:\n",
        "            dst = os.path.join(directory, \"downloads\", category)\n",
        "        os.makedirs(dst, exist_ok=True)\n",
        "        urls = [urls] if isinstance(urls, str) else urls\n",
        "        batch_download(urls, dst, quiet=True)\n",
        "\n",
        "def batch_download(urls, dst, desc=None, quiet=False):\n",
        "    for url in tqdm(urls, disable=quiet, desc=cprint(desc, color=\"green\", tqdm_desc=True)):\n",
        "        filename = get_filename(url, quiet=True)\n",
        "        aria2_download(url=url, download_dir=dst, filename=filename, quiet=True)\n",
        "\n",
        "def main():\n",
        "    annotator_dir = os.path.join(extensions_dir, \"sd-webui-controlnet\", \"annotator\")\n",
        "\n",
        "    if pre_download_annotator:\n",
        "        download_annotator(annotator_dir, \"ControlNet Annotator/Preprocessor\")\n",
        "    if control_v11_sd15_model:\n",
        "        batch_download(control_v11_sd15_url, control_dir, \"SDv1.x ControlNet Model\")\n",
        "    if t2i_adapter_model:\n",
        "        batch_download(t2i_adapter_url, control_dir, \"SDv1.x Text2Image Adapter Model\")\n",
        "    if control_v11_sd21_url:\n",
        "        batch_download(control_v11_sd21_url, control_dir, \"SDv1.x ControlNet Model\")\n",
        "            \n"
      ],
      "metadata": {
        "id": "K28QYTFhf7Cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **ControlNet v1.1** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#controlnet-v11)</small></small>\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "import yaml\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from urllib.parse import urlparse, unquote\n",
        "from datetime import timedelta\n",
        "from IPython.utils import capture\n",
        "from tqdm import tqdm\n",
        "\n",
        "# @markdown ### **ControlNet Annotator**\n",
        "pre_download_annotator = True  # @param {type: 'boolean'}\n",
        "# @markdown ### **SDv1.x ControlNet Model**\n",
        "control_v11_sd15_model = True  # @param {type: 'boolean'}\n",
        "t2i_adapter_model = False  # @param {type: 'boolean'}\n",
        "# @markdown ### **SDv2.x ControlNet Model**\n",
        "control_v11_sd21_model = False  # @param {type: 'boolean'}\n",
        "# @markdown ### **ControlNet Config**\n",
        "control_net_max_models_num = 2 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "config_file = os.path.join(repo_dir, \"config.json\")\n",
        "\n",
        "annotator_dict = {\n",
        "    \"oneformer\"     : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/150_16_swin_l_oneformer_coco_100ep.pth\",\n",
        "    \"oneformer\"     : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/250_16_swin_l_oneformer_ade20k_160k.pth\",\n",
        "    \"zoedepth\"      : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/ZoeD_M12_N.pt\",\n",
        "    \"midas\"         : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/dpt_beit_large_512.pt\",\n",
        "    \"midas\"         : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/dpt_hybrid-midas-501f0c75.pt\",\n",
        "    \"midas\"         : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/dpt_large-midas-2f21e586.pt\",\n",
        "    \"openpose\"      : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/facenet.pth\",\n",
        "    \"openpose\"      : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/hand_pose_model.pth\",\n",
        "    \"openpose\"      : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/body_pose_model.pth\",\n",
        "    \"keypose\"       : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\",\n",
        "    \"keypose\"       : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth\",\n",
        "    \"leres\"         : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/latest_net_G.pth\",\n",
        "    \"leres\"         : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/res101.pth\",\n",
        "    \"mlsd\"          : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/mlsd_large_512_fp32.pth\",\n",
        "    \"lineart_anime\" : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/netG.pth\",\n",
        "    \"hed\"           : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/network-bsds500.pth\",\n",
        "    \"normal_bae\"    : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/scannet.pt\",\n",
        "    \"lineart\"       : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/sk_model.pth\",\n",
        "    \"lineart\"       : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/sk_model2.pth\",\n",
        "    \"pidinet\"       : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/table5_pidinet.pth\",\n",
        "    \"uniformer\"     : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/upernet_global_small.pth\",\n",
        "}\n",
        "\n",
        "control_v11_sd15_url = [\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_lineart_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_openpose_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_scribble_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_seg_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_softedge_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11f1e_sd15_tile_fp16.safetensors\",\n",
        "]\n",
        "\n",
        "control_v11_sd21_url = [\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_ade20k.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_canny.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_color.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_depth.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_hed.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_lineart.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_normalbae.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_openpose.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_openposev2.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_scribble.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_zoedepth.safetensors\"\n",
        "]\n",
        "\n",
        "t2i_adapter_url = [\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd15v2.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_color_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd15v2.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_keypose_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_openpose_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_seg_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd15v2.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_style_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_zoedepth_sd15v1.pth\"\n",
        "]\n",
        "\n",
        "def cldm_config_path(destination_path):\n",
        "    if \"control\" in destination_path and \"sd15\" in destination_path:\n",
        "        if \"_shuffle_\" in destination_path:\n",
        "            return \"control_v11e_sd15_shuffle.yaml\"\n",
        "        else:\n",
        "            return \"cldm_v15.yaml\"\n",
        "    elif \"control\" in destination_path and \"sd21\"in destination_path: \n",
        "        return \"cldm_v21.yaml\"\n",
        "    elif \"t2i\" in destination_path:\n",
        "        adapter_name = os.path.splitext(os.path.basename(destination_path))[0]\n",
        "        return adapter_name + \".yaml\"\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def cldm_config(destination_path):\n",
        "    control_net_model_config = cldm_config_path(destination_path)\n",
        "    if control_net_model_config is not None:\n",
        "        cldm_config_src = os.path.join(extensions_dir, os.path.join(\"sd-webui-controlnet/models\", control_net_model_config))\n",
        "        cldm_config_dst = os.path.splitext(destination_path)[0] + \".yaml\"\n",
        "        if not os.path.exists(cldm_config_dst):\n",
        "            shutil.copy(cldm_config_src, cldm_config_dst)\n",
        "\n",
        "def download(url, destination_path, is_annotator=None):\n",
        "    hf_token = \"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\"\n",
        "    user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "    basename = os.path.basename(url)\n",
        "    dst_dir = os.path.join(os.path.dirname(control_dir), destination_path) if is_annotator else destination_path\n",
        "    os.makedirs(dst_dir, exist_ok=True)\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {dst_dir} -o {basename} {url}\n",
        "    cldm_config(os.path.join(dst_dir, basename))\n",
        "\n",
        "def batch(url, download_description, is_annotator=None):\n",
        "    if is_annotator:\n",
        "        for dest_path, url in tqdm(annotator_dict.items(), desc=f\"\u001b[1;32mDownloading {download_description}\"):\n",
        "            with capture.capture_output() as cap:\n",
        "                download(url, dest_path, is_annotator=True)\n",
        "                del cap\n",
        "    else:\n",
        "        for control in tqdm(url, desc=f\"\u001b[1;32mDownloading {download_description}\"):\n",
        "            with capture.capture_output() as cap:\n",
        "                download(control, control_dir, is_annotator=False)\n",
        "                del cap\n",
        "\n",
        "def main():\n",
        "    config = read_config(config_file)\n",
        "    config[\"control_net_max_models_num\"] = control_net_max_models_num\n",
        "    config[\"control_net_models_path\"] = control_dir\n",
        "    config[\"control_net_allow_script_control\"] = True\n",
        "    write_config(config_file, config)\n",
        "  \n",
        "    if pre_download_annotator:\n",
        "        batch(annotator_dict, \"ControlNet Annotator/Preprocessor\", is_annotator=True)\n",
        "    if control_v11_sd15_model:\n",
        "        batch(control_v11_sd15_url, \"SDv1.x ControlNet Model\", is_annotator=False)\n",
        "    if t2i_adapter_model:\n",
        "        batch(t2i_adapter_url, \"SDv1.x Text2Image Adapter Model\", is_annotator=False)\n",
        "    if control_v11_sd21_model:\n",
        "        batch(control_v11_sd21_url, \"SDv2.x ControlNet Model\", is_annotator=False)\n",
        "        \n",
        "print(f\"\u001b[1;32mDownloading...\")\n",
        "start_time = time.time()\n",
        "\n",
        "main()\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = int(end_time - start_time)\n",
        "\n",
        "if elapsed_time < 60:\n",
        "    print(f\"\\n\u001b[1;32mDownload completed. Took {elapsed_time} sec\")\n",
        "else:\n",
        "    mins, secs = divmod(elapsed_time, 60)\n",
        "    print(f\"\\n\u001b[1;32mDownload completed. Took {mins} mins {secs} sec\")\n",
        "\n",
        "print(\"\u001b[1;32mAll is done! Go to the next step\")"
      ],
      "metadata": {
        "id": "LKKtxDoIIg1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Custom Download Corner** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#custom-download-corner)</small></small>\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import glob\n",
        "import requests\n",
        "import gc\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from datetime import timedelta\n",
        "from urllib.parse import urlparse, unquote\n",
        "from IPython.utils import capture\n",
        "from tqdm import tqdm\n",
        "from safetensors.torch import load_file, save_file\n",
        "from torch import load, save\n",
        "import pickle as python_pickle\n",
        "\n",
        "%store -r\n",
        "\n",
        "# @markdown Fill in the URL fields with the links to the files you want to download. Separate multiple URLs with a comma.\n",
        "# @markdown Example: `url1, url2, url3`\n",
        "os.chdir(root_dir)\n",
        "\n",
        "custom_model_url = \"\"  # @param {'type': 'string'}\n",
        "custom_vae_url = \"\"  # @param {'type': 'string'}\n",
        "custom_embedding_url = \"\"  # @param {'type': 'string'}\n",
        "custom_LoRA_url = \"\"  # @param {'type': 'string'}\n",
        "custom_hypernetwork_url = \"\"  # @param {'type': 'string'}\n",
        "custom_extensions_url = \"\"  # @param {'type': 'string'}\n",
        "custom_upscaler_url = \"\"  # @param {'type': 'string'}\n",
        "\n",
        "custom_download_list = []\n",
        "\n",
        "custom_dirs = {\n",
        "    \"model\"       : models_dir,\n",
        "    \"vae\"         : vaes_dir,\n",
        "    \"embedding\"   : embeddings_dir,\n",
        "    \"LoRA\"        : lora_dir,\n",
        "    \"hypernetwork\": hypernetworks_dir,\n",
        "    \"extensions\"  : extensions_dir,\n",
        "    \"upscaler\"    : esrgan_dir,    \n",
        "}\n",
        "\n",
        "def is_safetensors(path):\n",
        "    return os.path.splitext(path)[1].lower() == '.safetensors'\n",
        "\n",
        "def extract(url, dst):\n",
        "    if not url.startswith(\"/content/\"):\n",
        "        filename = os.path.basename(url)\n",
        "        zipfile = os.path.join(dst, filename)\n",
        "    else:\n",
        "        zipfile = url\n",
        "\n",
        "    if url.endswith(\".zip\"):\n",
        "        if os.path.exists(zipfile):\n",
        "            !unzip -j -o {zipfile} -d \"{dst}\"\n",
        "            os.remove(zipfile)\n",
        "    elif url.endswith(\".tar.lz4\"):\n",
        "        if os.path.exists(zipfile):\n",
        "            !tar -xI lz4 -f {zipfile} --directory={dst}\n",
        "            os.remove(zipfile)\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "def unionfuse(folder_path, dst_dir):\n",
        "    try:\n",
        "        if \"extensions\" in category:\n",
        "            print(f\"\\n\u001b[1;32m{category.capitalize()} folder can't be fused, skipping...\")\n",
        "        else: \n",
        "            category_dir = os.path.join(os.path.join(root_dir,\"fused\"), category)\n",
        "            for dir in [folder_path, category_dir, dst_dir]:\n",
        "                os.makedirs(dir, exist_ok=True)\n",
        "            with capture.capture_output() as cap:    \n",
        "                !unionfs-fuse {dst_dir}=RW:\"{folder_path}\"=RW {category_dir}\n",
        "            output = cap.stdout.strip()\n",
        "            if \"fuse: mountpoint is not empty\" in output:\n",
        "                print(f\"\\n\u001b[1;32m{category.capitalize()} folder is not empty and can't be fused, skipping...\")\n",
        "            else:\n",
        "                print(f\"\\n\u001b[1;32m{category.capitalize()} folder fused successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n\u001b[1;32mAn error occurred while fusing the folders: {e}\")\n",
        "\n",
        "def prune_model(checkpoint, fp16=False, ema=False, clip=True, vae=True, depth=True, unet=True):\n",
        "    # Borrowed Lopho's code hehe\n",
        "    sd = checkpoint\n",
        "    nested_sd = False\n",
        "    if 'state_dict' in sd:\n",
        "        sd = sd['state_dict']\n",
        "        nested_sd = True\n",
        "    sd_pruned = dict()\n",
        "    for k in sd:\n",
        "        cp = unet and k.startswith('model.diffusion_model.')\n",
        "        cp = cp or (depth and k.startswith('depth_model.'))\n",
        "        cp = cp or (vae and k.startswith('first_stage_model.'))\n",
        "        cp = cp or (clip and k.startswith('cond_stage_model.'))\n",
        "        if cp:\n",
        "            k_in = k\n",
        "            if ema:\n",
        "                k_ema = 'model_ema.' + k[6:].replace('.', '')\n",
        "                if k_ema in sd:\n",
        "                    k_in = k_ema\n",
        "            sd_pruned[k] = sd[k_in].half() if fp16 else sd[k_in]\n",
        "    del sd\n",
        "\n",
        "    if nested_sd:\n",
        "        return {'state_dict': sd_pruned}\n",
        "    else:\n",
        "        return sd_pruned\n",
        "\n",
        "def autoprune(model_path, prefix):\n",
        "    def bytes_to_gb(size_in_bytes):\n",
        "        return size_in_bytes / (1024 * 1024 * 1024)\n",
        "\n",
        "    initial_size = bytes_to_gb(os.path.getsize(model_path))\n",
        "\n",
        "    print(f\"\\n\u001b[1;32mPruning model ({prefix}): {model_path} ({initial_size:.2f} GB)\")\n",
        "    if is_safetensors(model_path):\n",
        "        input_sd = load_file(model_path)\n",
        "    else:\n",
        "        input_sd = load(model_path)  # type: ignore\n",
        "\n",
        "    pruned = prune_model(input_sd, fp16=(prefix == \"fp16\"))\n",
        "\n",
        "    model_name, ext = os.path.splitext(model_path)\n",
        "    output_path = f\"{model_name}-{prefix}{ext}\"\n",
        "\n",
        "    if is_safetensors(model_path):\n",
        "        save_file(pruned, output_path)\n",
        "    else:\n",
        "        save(pruned, output_path)\n",
        "\n",
        "    if \"/content/drive/MyDrive/\" not in model_path:\n",
        "        os.remove(model_path)\n",
        "\n",
        "    del input_sd, pruned\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    final_size = bytes_to_gb(os.path.getsize(output_path))\n",
        "    print(f\"\u001b[1;32mPruning completed: {output_path} ({final_size:.2f} GB)\")\n",
        "\n",
        "def get_most_recent_file(directory):\n",
        "    files = glob.glob(os.path.join(directory, \"*\"))\n",
        "    if not files:\n",
        "        return None\n",
        "    most_recent_file = max(files, key=os.path.getmtime)\n",
        "    return most_recent_file\n",
        "\n",
        "def get_filename(url):\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    if 'content-disposition' in response.headers:\n",
        "        content_disposition = response.headers['content-disposition']\n",
        "        filename = re.findall('filename=\"?([^\"]+)\"?', content_disposition)[0]\n",
        "    else:\n",
        "        url_path = urlparse(url).path\n",
        "        filename = unquote(os.path.basename(url_path))\n",
        "        \n",
        "    return filename\n",
        "\n",
        "def download(url_list, dst_dir, is_extensions):\n",
        "    supported_extensions = [\".ckpt\", \".safetensors\", \".pt\", \".pth\"]\n",
        "\n",
        "    desc = f\"\u001b[1;32mDownloading Custom {category.capitalize()}\"\n",
        "    if category == \"extensions\":\n",
        "        desc = f\"\u001b[1;32mInstalling Custom {category.capitalize()}\"\n",
        "\n",
        "    for url in tqdm(url_list, desc=desc):\n",
        "        if url:\n",
        "            url = url.strip()\n",
        "            prune_prefix = None\n",
        "            if url.startswith(\"fp32:\"):\n",
        "                prune_prefix = \"fp32\"\n",
        "                url = url[5:].strip()\n",
        "            elif url.startswith(\"fp16:\"):\n",
        "                prune_prefix = \"fp16\"\n",
        "                url = url[5:].strip()\n",
        "                \n",
        "            if url.startswith(\"fuse:\"):\n",
        "                folder_path = url[5:].strip()\n",
        "                unionfuse(folder_path, dst_dir)\n",
        "            else:\n",
        "                custom_download_list.append(url)\n",
        "                if url.startswith(\"/content/drive/MyDrive/\") or url.endswith(tuple(supported_extensions)):\n",
        "                    basename = os.path.basename(url)\n",
        "                else:\n",
        "                    basename = get_filename(url)\n",
        "\n",
        "                with capture.capture_output() as cap:\n",
        "                    if is_extensions:\n",
        "                        os.chdir(extensions_dir)\n",
        "                        if os.path.exists(basename):\n",
        "                            shutil.rmtree(os.path.join(extensions_dir, basename))\n",
        "                        !git clone {url}\n",
        "                    elif url.startswith(\"/content/drive/MyDrive/\"):\n",
        "                        Path(os.path.join(dst_dir, basename)).write_bytes(Path(url).read_bytes())\n",
        "                    elif \"drive.google.com\" in url:\n",
        "                        if \"folders\" in url:\n",
        "                            !gdown --folder \"{url}\" -O {dst_dir} --fuzzy -c\n",
        "                        else:\n",
        "                            !gdown \"{url}\" -O {dst_dir} --fuzzy -c\n",
        "                    elif \"huggingface.co\" in url:\n",
        "                        if \"/blob/\" in url:\n",
        "                            url = url.replace(\"/blob/\", \"/resolve/\")\n",
        "                        hf_token = \"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\"\n",
        "                        user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "                        !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {dst_dir} -o {basename} {url}\n",
        "                    elif any(url.endswith(extension) for extension in supported_extensions):\n",
        "                        !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {dst_dir} -o {basename} {url}\n",
        "                    else:\n",
        "                        !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {dst_dir} {url}\n",
        "\n",
        "                    extract(url, dst_dir)\n",
        "                del cap\n",
        "\n",
        "            if prune_prefix:\n",
        "                if \"model\" in category:\n",
        "                    try:\n",
        "                        if any(basename.endswith(extension) for extension in supported_extensions):\n",
        "                            model_path = os.path.join(dst_dir, basename)\n",
        "                            autoprune(model_path, prune_prefix)\n",
        "                        else:\n",
        "                            most_recent_file = get_most_recent_file(dst_dir)\n",
        "                            if most_recent_file is not None:\n",
        "                                autoprune(most_recent_file, prune_prefix)\n",
        "                    except Exception as e:\n",
        "                        print(f\"\\n\u001b[1;32mError pruning file: {e}\")\n",
        "                else:\n",
        "                    print(f\"\\n\u001b[1;32mOnly model can be pruned, skipping...\")\n",
        "\n",
        "print(f\"\u001b[1;32mDownloading...\")\n",
        "start_time = time.time()\n",
        "\n",
        "for category, custom_url in [\n",
        "    (\"model\", custom_model_url),\n",
        "    (\"vae\", custom_vae_url),\n",
        "    (\"embedding\", custom_embedding_url),\n",
        "    (\"LoRA\", custom_LoRA_url),\n",
        "    (\"hypernetwork\", custom_hypernetwork_url),\n",
        "    (\"extensions\", custom_extensions_url),\n",
        "    (\"upscaler\", custom_upscaler_url),\n",
        "]:\n",
        "    if custom_url:\n",
        "        urls = custom_url.split(\",\")\n",
        "        download(urls, custom_dirs[category], category == \"extensions\")\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = int(end_time - start_time)\n",
        "\n",
        "print()\n",
        "if elapsed_time < 60:\n",
        "    print(f\"\u001b[1;32mDownload completed. Took {elapsed_time} sec\")\n",
        "else:\n",
        "    mins, secs = divmod(elapsed_time, 60)\n",
        "    print(f\"\u001b[1;32mDownload completed. Took {mins} mins {secs} sec\")\n",
        "\n",
        "print(\"\u001b[1;32mAll is done! Go to the next step\")\n",
        "\n",
        "custom_download_list = []"
      ],
      "metadata": {
        "id": "PdjuRPcX0-Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaAJk33ppFw1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ## **Start Cagliostro Colab UI** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#start-stable-diffusion-web-ui)</small></small>\n",
        "import os\n",
        "import random\n",
        "import string\n",
        "from pyngrok import ngrok, conf\n",
        "%store -r \n",
        "\n",
        "# @markdown ### **Alternative Tunnel**\n",
        "\n",
        "# @markdown > Recommended Tunnels: `ngrok` > `cloudflared` > `remotemoe` > `localhostrun` > `googleusercontent` > `gradio`\n",
        "tunnel              = \"cloudflared\" # @param ['none', 'multiple','cloudflared', 'localhostrun', 'remotemoe', \"googleusercontent\"]\n",
        "# @markdown > Get <b>your</b> token for ngrok [here](https://dashboard.ngrok.com/get-started/your-authtoken) \n",
        "ngrok_token         = \"\" # @param {type: 'string'}\n",
        "ngrok_region        = \"ap\" # @param [\"us\", \"eu\", \"au\", \"ap\", \"sa\", \"jp\", \"in\"]\n",
        "# @markdown ### **UI Config**\n",
        "use_dark_theme      = True # @param {type: 'boolean'}\n",
        "theme               = \"minimal_orange\" # @param ['moonlight', 'ogxRed', 'fun', 'ogxCyan', 'ogxCyanInvert', 'ogxBGreen', 'default_orange', 'tron2', 'd-230-52-94', 'minimal', 'ogxRedYellow', 'retrog', 'ogxRedPurple', 'ogxGreen', 'tron', 'default_cyan', 'default', 'backup', 'minimal_orange', 'Golde']\n",
        "# @markdown Set `use_preset` for using default prompt, resolution, sampler, and other settings\n",
        "use_presets         = True # @param {type: 'boolean'}\n",
        "# @markdown ### **Arguments**\n",
        "use_gradio_auth     = False # @param {type: 'boolean'}\n",
        "accelerator         = \"xformers\" # @param ['xformers', 'opt-sdp-attention', 'opt-split-attention']\n",
        "auto_select_model   = False # @param {type: 'boolean'}\n",
        "auto_select_VAE     = True # @param {type: 'boolean'}\n",
        "additional_args     = \"--lowram --no-half-vae\" #@param {type: 'string'}\n",
        "\n",
        "config_file         = os.path.join(repo_dir, \"config.json\")\n",
        "ui_config_file      = os.path.join(repo_dir, \"ui-config.json\")\n",
        "voldemort           = base64.b64decode((\"'c3RhYmxlLWRpZmZ1c2lvbi13ZWJ1aQ=='\").encode('ascii')).decode('ascii')\n",
        "\n",
        "user                = \"cagliostro\"\n",
        "password            = \"\".join(random.choices(string.ascii_letters + string.digits, k=6))\n",
        "\n",
        "default_prompt      = \"masterpiece, best quality,\"\n",
        "default_neg_prompt  = \"(worst quality, low quality:1.4)\"\n",
        "default_sampler     = \"DPM++ 2M Karras\"\n",
        "if dpm_v2_patch:\n",
        "    default_sampler = \"DPM++ 2M Karras v2\" \n",
        "default_steps       = 20\n",
        "default_width       = 512\n",
        "default_height      = 768\n",
        "default_strength    = 0.55\n",
        "default_cfg_scale   = 7\n",
        "default_clip_skip   = 2\n",
        "quicksettings       = \"sd_model_checkpoint, sd_vae, CLIP_stop_at_last_layers, use_old_karras_scheduler_sigmas, always_discard_next_to_last_sigma\"\n",
        "\n",
        "def read_config(filename):\n",
        "    if filename.endswith(\".json\"):\n",
        "        with open(filename, \"r\") as f:\n",
        "          config = json.load(f)\n",
        "    else:\n",
        "        with open(filename, 'r') as f:\n",
        "          config = f.read()\n",
        "\n",
        "    return config\n",
        "\n",
        "def write_config(filename, config):\n",
        "    if filename.endswith(\".json\"):\n",
        "        with open(filename, \"w\") as f:\n",
        "            json.dump(config, f, indent=4)\n",
        "    else:\n",
        "        with open(filename, 'w', encoding=\"utf-8\") as f:\n",
        "            f.write(config)\n",
        "            f.close()  \n",
        "\n",
        "def change_theme(filename):\n",
        "    themes_folder       = os.path.join(repo_dir, \"extensions-builtin/sd_theme_editor/themes\")\n",
        "    themes_file         = os.path.join(themes_folder, f\"{filename}.css\")\n",
        "    style_path          = os.path.join(repo_dir, \"style.css\")\n",
        "\n",
        "    style_config        = read_config(style_path)\n",
        "    style_css_contents  = style_config.split(\"/*BREAKPOINT_CSS_CONTENT*/\")[1]\n",
        "\n",
        "    theme_config        = read_config(themes_file)\n",
        "    style_data          = \":host{\" + theme_config + \"}\" + \"/*BREAKPOINT_CSS_CONTENT*/\" + style_css_contents\n",
        "\n",
        "    write_config(style_path, style_data)\n",
        "\n",
        "def configure_tunnel(ngrok_token):\n",
        "    share = True\n",
        "    if ngrok_token:\n",
        "        ngrok.kill()\n",
        "        srv = ngrok.connect(7860, pyngrok_config=conf.PyngrokConfig(auth_token=ngrok_token), bind_tls=True).public_url\n",
        "        update_gradio_blocks(srv)\n",
        "        share = False\n",
        "        tunnel = \"none\"\n",
        "    return share\n",
        "\n",
        "def update_gradio_blocks(srv):\n",
        "    gradio_blocks_file = \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\"\n",
        "    gradio_strings_file = \"/usr/local/lib/python3.10/dist-packages/gradio/strings.py\"\n",
        "\n",
        "    search_text   = \"Running on local URL:  {}://{}:{}\"\n",
        "    replace_text  = \"Running on NGROK:  {}://{}\"\n",
        "\n",
        "    with fileinput.input(gradio_blocks_file, inplace=True) as f:\n",
        "        for line in f:\n",
        "            if line.strip().startswith('self.server_name ='):\n",
        "                line = f'            self.server_name = \"{srv[8:]}\"\\n'\n",
        "            sys.stdout.write(line)\n",
        "\n",
        "    with fileinput.input(gradio_strings_file, inplace=True) as f:\n",
        "        for line in f:\n",
        "            if search_text in line:\n",
        "                line = line.replace(search_text, replace_text)\n",
        "            sys.stdout.write(line)\n",
        "\n",
        "def is_dir_exist(cloned_dir, original_dir):\n",
        "    if os.path.exists(cloned_dir):\n",
        "        return cloned_dir \n",
        "    else:\n",
        "        return original_dir\n",
        "\n",
        "repo_name, *_           = validate_repo(repo_dir)\n",
        "valid_ckpt_dir          = is_dir_exist(os.path.join(fused_dir, \"model\"), models_dir)\n",
        "valid_vae_dir           = is_dir_exist(os.path.join(fused_dir, \"vae\"), vaes_dir)\n",
        "valid_embedding_dir     = is_dir_exist(os.path.join(fused_dir, \"embedding\"), embeddings_dir)\n",
        "valid_lora_dir          = is_dir_exist(os.path.join(fused_dir, \"LoRA\"), lora_dir)\n",
        "valid_hypernetwork_dir  = is_dir_exist(os.path.join(fused_dir, \"hypernetwork\"), hypernetworks_dir)\n",
        "\n",
        "if auto_select_model:\n",
        "    model_path  = \"dummy.ckpt\"\n",
        "    models_list = os.listdir(valid_ckpt_dir)\n",
        "    model_files = [f for f in models_list if f.endswith(('.ckpt','.safetensors'))]\n",
        "    if model_files:\n",
        "        model_path = random.choice(model_files)\n",
        "        if os.path.exists(os.path.join(valid_ckpt_dir, model_path)):\n",
        "            config = read_config(config_file)\n",
        "            config[\"sd_model_checkpoint\"] = model_path\n",
        "            write_config(config_file, config)\n",
        "\n",
        "if auto_select_VAE:\n",
        "    vae_path  = \"dummy.pt\"\n",
        "    vaes_list = os.listdir(valid_vae_dir)\n",
        "    vae_files = [f for f in vaes_list if f.endswith('.vae.pt')]\n",
        "    if vae_files:\n",
        "        vae_path = random.choice(vae_files)\n",
        "        if os.path.exists(os.path.join(valid_vae_dir, vae_path)):\n",
        "            config = read_config(config_file)\n",
        "            config[\"sd_vae\"] = vae_path\n",
        "            write_config(config_file, config) \n",
        "\n",
        "# config.json\n",
        "if use_presets:\n",
        "    ui_config = read_config(ui_config_file)\n",
        "    ui_config_dict = {\n",
        "        \"txt2img/Prompt/value\"            : default_prompt,\n",
        "        \"txt2img/Negative prompt/value\"   : default_neg_prompt,\n",
        "        \"txt2img/Sampling method/value\"   : default_sampler,\n",
        "        \"txt2img/Sampling steps/value\"    : default_steps,\n",
        "        \"txt2img/Width/value\"             : default_width,\n",
        "        \"txt2img/Height/value\"            : default_height,\n",
        "        \"txt2img/Upscaler/value\"          : \"Latent (nearest-exact)\",\n",
        "        \"txt2img/Denoising strength/value\": default_strength,\n",
        "        \"txt2img/CFG Scale/value\"         : default_cfg_scale,\n",
        "        \"img2img/Prompt/value\"            : default_prompt,\n",
        "        \"img2img/Negative prompt/value\"   : default_neg_prompt,\n",
        "        \"img2img/Sampling method/value\"   : default_sampler,\n",
        "        \"img2img/Sampling steps/value\"    : default_steps,\n",
        "        \"img2img/Width/value\"             : default_width,\n",
        "        \"img2img/Height/value\"            : default_height,\n",
        "        \"img2img/Denoising strength/value\": default_strength,\n",
        "        \"img2img/CFG Scale/value\"         : default_cfg_scale\n",
        "    }\n",
        "    ui_config.update(ui_config_dict)\n",
        "    write_config(ui_config_file, ui_config)\n",
        "\n",
        "if repo_name == \"vladmandic/automatic\":\n",
        "    share_var       = configure_tunnel(ngrok_token)\n",
        "    additional_args = \"\"\n",
        "\n",
        "    general_config  = read_config(config_file)\n",
        "    general_dict    = {\n",
        "        \"additional_networks_extra_lora_path\": valid_lora_dir,\n",
        "        \"ckpt_dir\"                           : valid_ckpt_dir,\n",
        "        \"vae_dir\"                            : valid_vae_dir,\n",
        "        \"embeddings_dir\"                     : valid_embedding_dir,\n",
        "        \"hypernetwork_dir\"                   : valid_hypernetwork_dir,\n",
        "        \"lora_dir\"                           : valid_lora_dir,\n",
        "        \"lyco_dir\"                           : valid_lora_dir,\n",
        "        \"CLIP_stop_at_last_layers\"           : default_clip_skip,\n",
        "        \"gradio_theme\"                       : \"ParityError/Anime\",\n",
        "        \"quicksettings\"                      : \"sd_model_checkpoint, sd_vae\"\n",
        "    }\n",
        "    general_config.update(general_dict)\n",
        "    write_config(config_file, general_config)\n",
        "\n",
        "    clip_skip_config  = read_config(ui_config_file)\n",
        "    clip_skip_dict    = {\n",
        "        \"txt2img/CLIP Skip/value\": default_clip_skip,\n",
        "        \"img2img/CLIP Skip/value\": default_clip_skip\n",
        "    }\n",
        "    clip_skip_config.update(clip_skip_dict)\n",
        "    write_config(ui_config_file, clip_skip_config)\n",
        "\n",
        "    launch_config = {\n",
        "        \"insecure\"                    : True,\n",
        "        \"disable-safe-unpickle\"       : True,\n",
        "        f\"{tunnel}\"                   : True if not tunnel in [\"multiple\", \"none\"] and not ngrok_token else False,\n",
        "        \"share\"                       : share_var,\n",
        "        \"no-download\"                 : True,\n",
        "        \"lowram\"                      : True,\n",
        "        \"auth\"                        : f\"{user}:{password}\" if use_gradio_auth else None,\n",
        "        \"no-hashing\"                  : True,\n",
        "        \"disable-console-progressbars\": True,\n",
        "        \"theme\"                       : \"dark\" if use_dark_theme else \"light\",\n",
        "    }\n",
        "\n",
        "else:\n",
        "    general_config = read_config(config_file)\n",
        "    general_dict = {\n",
        "        \"additional_networks_extra_lora_path\" : valid_lora_dir,\n",
        "        \"CLIP_stop_at_last_layers\"            : default_clip_skip,\n",
        "        \"eta_noise_seed_delta\"                : 0,\n",
        "        \"show_progress_every_n_steps\"         : 10,\n",
        "        \"show_progressbar\"                    : True,\n",
        "        \"quicksettings_list\"                  : [setting.strip() for setting in quicksettings.split(\",\")]\n",
        "    }\n",
        "    general_config.update(general_dict)\n",
        "    write_config(config_file, general_config)\n",
        "\n",
        "    launch_config = {\n",
        "        \"enable-insecure-extension-access\"  : True,\n",
        "        \"disable-safe-unpickle\"             : True,\n",
        "        f\"{accelerator}\"                    : True,\n",
        "        f\"{tunnel}\"                         : True if not tunnel in [\"bore\", \"none\"] and not ngrok_token else False,\n",
        "        \"share\"                             : True if not ngrok_token else False,\n",
        "        \"gradio-auth\"                       : f\"{user}:{password}\" if use_gradio_auth else None,\n",
        "        \"no-hashing\"                        : True,\n",
        "        \"disable-console-progressbars\"      : True,\n",
        "        \"ngrok\"                             : ngrok_token if ngrok_token else None,\n",
        "        \"ngrok-region\"                      : ngrok_region if ngrok_token else None,\n",
        "        \"opt-sub-quad-attention\"            : True,\n",
        "        \"opt-channelslast\"                  : True,\n",
        "        \"theme\"                             : \"dark\" if use_dark_theme else \"light\",\n",
        "        \"no-download-sd-model\"              : True,\n",
        "        \"gradio-queue\"                      : True,\n",
        "        \"listen\"                            : True,\n",
        "        \"ckpt-dir\"                          : valid_ckpt_dir,\n",
        "        \"vae-dir\"                           : valid_vae_dir,\n",
        "        \"hypernetwork-dir\"                  : valid_hypernetwork_dir,\n",
        "        \"embeddings-dir\"                    : valid_embedding_dir,\n",
        "        \"lora-dir\"                          : valid_lora_dir,\n",
        "        \"lyco-dir\"                          : valid_lora_dir,\n",
        "    }\n",
        "    if repo_name == f\"anapnoe/{voldemort}-ux\":\n",
        "        change_theme(theme)\n",
        "\n",
        "print(\"\u001b[1;32m\")\n",
        "\n",
        "if use_gradio_auth:\n",
        "      print(\"Gradio Auth (use this account to login):\")\n",
        "      print(\"- Username: cagliostro\")\n",
        "      print(\"- Password:\", password)\n",
        "      print(\"\\n\\n\")\n",
        "\n",
        "args = \"\"\n",
        "for k, v in launch_config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python launch.py {args} {additional_args}\"\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Download Generated Images** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#download-generated-images)</small></small>\n",
        "# @markdown Download file manually from files tab or save to Google Drive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from google.colab import drive\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(drive_dir)\n",
        "\n",
        "use_drive = True  # @param {type:\"boolean\"}\n",
        "folder_name = \"cagliostro-colab-ui\"  # @param {type: \"string\"}\n",
        "filename = \"waifu.zip\"  # @param {type: \"string\"}\n",
        "save_as = filename\n",
        "\n",
        "if os.path.exists(filename):\n",
        "    i = 1\n",
        "    while os.path.exists(f\"waifu({i}).zip\"):\n",
        "        i += 1\n",
        "    filename = f\"waifu({i}).zip\"\n",
        "\n",
        "!zip -r /content/outputs.zip .\n",
        "\n",
        "if use_drive:\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "\n",
        "    def create_folder(folder_name):\n",
        "        file_list = drive.ListFile(\n",
        "            {\n",
        "                \"q\": \"title='{}' and mimeType='application/vnd.google-apps.folder' and trashed=false\".format(\n",
        "                    folder_name\n",
        "                )\n",
        "            }\n",
        "        ).GetList()\n",
        "        if len(file_list) > 0:\n",
        "            print(\"Debug: Folder exists\")\n",
        "            folder_id = file_list[0][\"id\"]\n",
        "        else:\n",
        "            print(\"Debug: Creating folder\")\n",
        "            file = drive.CreateFile(\n",
        "                {\"title\": folder_name, \"mimeType\": \"application/vnd.google-apps.folder\"}\n",
        "            )\n",
        "            file.Upload()\n",
        "            folder_id = file.attr[\"metadata\"][\"id\"]\n",
        "        return folder_id\n",
        "\n",
        "    def upload_file(file_name, folder_id, save_as):\n",
        "        file_list = drive.ListFile(\n",
        "            {\"q\": \"title='{}' and trashed=false\".format(save_as)}\n",
        "        ).GetList()\n",
        "        if len(file_list) > 0:\n",
        "            print(\"Debug: File already exists\")\n",
        "            i = 1\n",
        "            while True:\n",
        "                new_name = (\n",
        "                    os.path.splitext(save_as)[0]\n",
        "                    + f\"({i})\"\n",
        "                    + os.path.splitext(save_as)[1]\n",
        "                )\n",
        "                file_list = drive.ListFile(\n",
        "                    {\"q\": \"title='{}' and trashed=false\".format(new_name)}\n",
        "                ).GetList()\n",
        "                if len(file_list) == 0:\n",
        "                    save_as = new_name\n",
        "                    break\n",
        "                i += 1\n",
        "        file = drive.CreateFile({\"title\": save_as, \"parents\": [{\"id\": folder_id}]})\n",
        "        file.SetContentFile(file_name)\n",
        "        file.Upload()\n",
        "        file.InsertPermission({\"type\": \"anyone\", \"value\": \"anyone\", \"role\": \"reader\"})\n",
        "        return file.attr[\"metadata\"][\"id\"]\n",
        "\n",
        "    file_id = upload_file(\"/content/outputs.zip\", create_folder(folder_name), save_as)\n",
        "    print(\n",
        "        \"Your sharing link: https://drive.google.com/file/d/\"\n",
        "        + file_id\n",
        "        + \"/view?usp=sharing\"\n",
        "    )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ojb4nAieATxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extras"
      ],
      "metadata": {
        "id": "4SUHPtGLz2m4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Download Generated Images V2** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#download-generated-images-v2)</small></small>\n",
        "from IPython.utils import capture\n",
        "from huggingface_hub import login\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# @markdown Download your output by upload it to **Huggingface** instead of Google Drive.\n",
        "# @markdown > Get **your** huggingface `WRITE` token [here](https://huggingface.co/settings/tokens)\n",
        "write_token = \"\"  # @param {type:\"string\"}\n",
        "# @markdown Specify where is your repo located, it will automatically create your repo if you didn't have one.\n",
        "repo_name = \"cagliostro-colab-ui\"  # @param{type:\"string\"}\n",
        "repo_name = repo_name.replace(\" \", \"-\")\n",
        "private_repo = False  # @param{type:\"boolean\"}\n",
        "# @markdown This will be compressed to zip and uploaded to datasets repo\n",
        "project_name = \"waifu\"  # @param {type :\"string\"}\n",
        "project_name = project_name.replace(\" \", \"_\")\n",
        "\n",
        "if not project_name:\n",
        "    project_name = \"waifu\"\n",
        "\n",
        "dataset_zip = project_name + \".zip\"\n",
        "output_path = os.path.join(root_dir, dataset_zip)\n",
        "commit_message = \"Feat: Upload \" + dataset_zip + \" with Cagliostro Colab UI\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    login(write_token, add_to_git_credential=True)\n",
        "output = cap.stdout.strip()\n",
        "if \"Token is valid.\" in output:\n",
        "    print(\"\u001b[1;32mLogin Succesful.\")\n",
        "\n",
        "api = HfApi()\n",
        "user = api.whoami(write_token)\n",
        "\n",
        "datasets_repo = user[\"name\"] + \"/\" + repo_name.strip()\n",
        "\n",
        "if repo_name:\n",
        "    try:\n",
        "        validate_repo_id(datasets_repo)\n",
        "        api.create_repo(\n",
        "            repo_id=datasets_repo, repo_type=\"dataset\", private=private_repo\n",
        "        )\n",
        "        print(\n",
        "            f\"\u001b[1;32mRepo created, located at https://huggingface.co/datasets/{datasets_repo}\"\n",
        "        )\n",
        "\n",
        "    except HfHubHTTPError as e:\n",
        "        print(f\"\u001b[1;32mRepo exist, skipping...\")\n",
        "\n",
        "os.chdir(drive_dir)\n",
        "print(f\"\u001b[1;32mCompressing to ZIP...\")\n",
        "with capture.capture_output() as cap:\n",
        "    !zip -rv {output_path} .\n",
        "\n",
        "print(f\"\u001b[1;32mUploading generated images... Please wait...\")\n",
        "\n",
        "api.upload_file(\n",
        "    path_or_fileobj=output_path,\n",
        "    path_in_repo=dataset_zip,\n",
        "    repo_id=datasets_repo,\n",
        "    repo_type=\"dataset\",\n",
        "    commit_message=commit_message,\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"\u001b[1;32mUpload success, download directly at https://huggingface.co/datasets/{datasets_repo}/resolve/main/{dataset_zip}\"\n",
        ")\n",
        "\n",
        "os.remove(output_path)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EGXqJLXwnJQB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}